{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Network Constrained Linear Optimal Power Flow - with Floating Wind & Marine, and Emissions Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, floating wind, wave power, tidal stream and tidal lagoon are considered specifically.  After the optimisation, the greenhouse gas emissions of the period under consideration are calculated for the whole grid, and for each node.\n",
    "\n",
    "The emissions calculation relies on emissions intensity factors for each type of generation - due to the signficant differences between certain types within a carrier.  This input data is provided from literature review."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "src_path = os.environ.get('PROJECT_SRC')\n",
    "os.chdir(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import data_reader_writer\n",
    "import generators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Simulation Period"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the required inputs for the LOPF: the start, end and year of simulation, and the timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv files for import\n",
    "start = '2050-02-27 00:00:00'\n",
    "end = '2050-03-01 23:30:00'\n",
    "# year of simulation\n",
    "year = int(start[0:4])\n",
    "# time step as fraction of hour (default set to one hour to reduce computation)\n",
    "time_step = 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Future Energy Scenario"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose from one of the National Grid Future Energy Scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 'Consumer Transformation'\n",
    "scenario = 'Leading The Way'\n",
    "# scenario = 'Steady Progression'\n",
    "# scenario = 'System Transformation'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a baseline year (from 2010-2020). The baseline year determines which historical load profile and weather dataset is used for the future year modelled. The National Grid FES modellers used 2012 as their baseline year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_baseline = 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scenario file naming convention for saving outputs later\n",
    "# SC = ''.join(c for c in scenario if c.isupper())\n",
    "# s = SC + start + end + str(year_baseline)\n",
    "# for char in string.punctuation:\n",
    "#     s = s.replace(char,'')\n",
    "#     s = s.replace(\" \",'')\n",
    "# filename = s + '.png'\n",
    "# powername = s + '_power.csv'\n",
    "# print(filename)\n",
    "# print(powername)\n",
    "\n",
    "# need to set up figures for power, emissions, map...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'C:\\Users\\s1100626/OneDrive - University of Edinburgh\\Year 2 - Energy System Modelling\\Q4 - Results\\Results'\n",
    "# fullpath = os.path.join(path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alyden\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:741: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  warnings.warn(\n",
      "c:\\Users\\alyden\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\alyden\\OneDrive - University of Edinburgh\\Python\\PyPSA-GB v0.0.1\\PyPSA-GB\\interconnectors.py:206: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df_FES = df_FES[~df_FES.Variable.str.contains('(TWh)')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alyden\\OneDrive - University of Edinburgh\\Python\\PyPSA-GB v0.0.1\\notebooks\\5X - LOPF Future - FWME - Working.ipynb Cell 18\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alyden/OneDrive%20-%20University%20of%20Edinburgh/Python/PyPSA-GB%20v0.0.1/notebooks/5X%20-%20LOPF%20Future%20-%20FWME%20-%20Working.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data_reader_writer\u001b[39m.\u001b[39mdata_writer(start, end, time_step, year, demand_dataset\u001b[39m=\u001b[39mdemand_dataset, year_baseline\u001b[39m=\u001b[39myear_baseline,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alyden/OneDrive%20-%20University%20of%20Edinburgh/Python/PyPSA-GB%20v0.0.1/notebooks/5X%20-%20LOPF%20Future%20-%20FWME%20-%20Working.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                scenario\u001b[39m=\u001b[39mscenario, FES\u001b[39m=\u001b[39m\u001b[39m2022\u001b[39m,  merge_generators\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, marine_modify\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, marine_scenario\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alyden/OneDrive%20-%20University%20of%20Edinburgh/Python/PyPSA-GB%20v0.0.1/notebooks/5X%20-%20LOPF%20Future%20-%20FWME%20-%20Working.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39madd_P2G\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alyden/OneDrive%20-%20University%20of%20Edinburgh/Python/PyPSA-GB%20v0.0.1/notebooks/5X%20-%20LOPF%20Future%20-%20FWME%20-%20Working.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m add_P2G\u001b[39m.\u001b[39;49madd_P2G(year, scenario\u001b[39m=\u001b[39;49mscenario)\n",
      "File \u001b[1;32mc:\\Users\\alyden\\OneDrive - University of Edinburgh\\Python\\PyPSA-GB v0.0.1\\notebooks\\add_P2G.py:62\u001b[0m, in \u001b[0;36madd_P2G\u001b[1;34m(year, scenario, path, replace)\u001b[0m\n\u001b[0;32m     60\u001b[0m df_P2G \u001b[39m=\u001b[39m df_FES_bb[(df_FES_bb[\u001b[39m'\u001b[39m\u001b[39mFES Scenario\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mscenario) \u001b[39m&\u001b[39m (df_FES_bb[\u001b[39m'\u001b[39m\u001b[39mBuilding Block ID Number\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDem_BB009\u001b[39m\u001b[39m'\u001b[39m)]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     61\u001b[0m df_P2G\u001b[39m.\u001b[39minsert(\u001b[39m6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbus\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m---> 62\u001b[0m df_P2G[\u001b[39m'\u001b[39;49m\u001b[39mbus\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m df_P2G\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m r: gsp_to_bus(r, df_gsp_data), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     63\u001b[0m df_P2G_year \u001b[39m=\u001b[39m df_P2G\u001b[39m.\u001b[39mgroupby(df_P2G\u001b[39m.\u001b[39mbus)\u001b[39m.\u001b[39msum()[year]\n\u001b[0;32m     65\u001b[0m p_available \u001b[39m=\u001b[39m pd_generators_p_max_pu\u001b[39m.\u001b[39mmultiply(pd_generators\u001b[39m.\u001b[39mloc[pd_generators\u001b[39m.\u001b[39mindex[pd_generators\u001b[39m.\u001b[39mcarrier\u001b[39m.\u001b[39misin(carrier_list)], \u001b[39m'\u001b[39m\u001b[39mp_nom\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\alyden\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\frame.py:3599\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3598\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3599\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_frame_value(key, value)\n\u001b[0;32m   3600\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(value) \u001b[39mand\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m   3601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_indexer_for([key])\n\u001b[0;32m   3602\u001b[0m ) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value):\n\u001b[0;32m   3603\u001b[0m     \u001b[39m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3604\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32mc:\\Users\\alyden\\Anaconda3\\envs\\PyPSA-GB\\lib\\site-packages\\pandas\\core\\frame.py:3724\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3722\u001b[0m len_cols \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m is_scalar(cols) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(cols)\n\u001b[0;32m   3723\u001b[0m \u001b[39mif\u001b[39;00m len_cols \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m-> 3724\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3726\u001b[0m \u001b[39m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[0;32m   3727\u001b[0m \u001b[39m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[0;32m   3728\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m   3729\u001b[0m     loc, (\u001b[39mslice\u001b[39m, Series, np\u001b[39m.\u001b[39mndarray, Index)\n\u001b[0;32m   3730\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "if year >= 2040:\n",
    "    demand_dataset = 'eload'\n",
    "else:\n",
    "    demand_dataset = 'historical' \n",
    "data_reader_writer.data_writer(start, end, time_step, year, demand_dataset=demand_dataset, year_baseline=year_baseline,\n",
    "                               scenario=scenario, FES=2022,  merge_generators=True, marine_modify=True, marine_scenario='Low')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Optimisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can introduce new marine scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pypsa.Network()\n",
    "network.import_from_csv_folder('LOPF_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generators = network.generators\n",
    "generators_p_nom = df_generators.p_nom.groupby(\n",
    "    df_generators.carrier).sum().sort_values()\n",
    "if year > 2020:\n",
    "    generators_p_nom.drop('Unmet Load', inplace=True)\n",
    "marine = generators_p_nom.loc[['Tidal lagoon', 'Tidal stream', 'Wave power']]\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "# bar chart\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(marine.index, marine.values / 1000)\n",
    "plt.xticks(marine.index, rotation=90)\n",
    "plt.ylabel('GW')\n",
    "plt.grid(color='grey', linewidth=1, axis='both', alpha=0.5)\n",
    "plt.title('Installed capacity in year ' + str(year) + ' under ' + scenario)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(marine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines need to be scaled up to accommodate for future generation. An arbitrary value of 4 is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_factor = 4\n",
    "network.lines.s_max_pu *= contingency_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lopf(network.snapshots, solver_name=\"gurobi\", pyomo=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power by Generation Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real power output is interrogated by generation type.  The total contribution to the grid wide generation is reported over the simulation period.  Nodal contributions are analysed in the emissions modelling section.\n",
    "\n",
    "Note that there is a difference in terminology between generators and storage types; it is storage carriers that are plotted, however they are described as storage 'types'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataframe containing time series of real power generated, arranged by generation and storage types\n",
    "p_by_type = network.generators_t.p.groupby(network.generators.type, axis=1).sum()\n",
    "\n",
    "# Combining Hydro types into a single category and removing \n",
    "p_by_type['Hydro'] = (p_by_type['Small Hydro'] + p_by_type['Large Hydro'])\n",
    "\n",
    "p_by_type.drop('Small Hydro', axis=1, inplace=True)\n",
    "p_by_type.drop('Large Hydro', axis=1, inplace=True)\n",
    "\n",
    "# Combining Diesel/Gas oil types into a single category and removing \n",
    "p_by_type['Diesel'] = (p_by_type['Diesel/Gas oil'] + p_by_type['Diesel/gas Diesel/Gas oil'])\n",
    "\n",
    "p_by_type.drop('Diesel/Gas oil', axis=1, inplace=True)\n",
    "p_by_type.drop('Diesel/gas Diesel/Gas oil', axis=1, inplace=True)\n",
    "\n",
    "# Combining Nuclear types into a single category and removing \n",
    "p_by_type['Nuclear'] = (p_by_type['AGR'] + p_by_type['PWR'])\n",
    "\n",
    "p_by_type.drop('AGR', axis=1, inplace=True)\n",
    "p_by_type.drop('PWR', axis=1, inplace=True)\n",
    "\n",
    "# Sorting generation types alphabetically\n",
    "p_by_type = p_by_type[sorted(p_by_type.columns)]\n",
    "\n",
    "# concatenating storage types\n",
    "storage_by_type = network.storage_units_t.p.groupby(network.storage_units.carrier, axis=1).sum()\n",
    "p_by_type = pd.concat([p_by_type, storage_by_type], axis=1)\n",
    "\n",
    "# Including Interconnectors Import\n",
    "imp = network.links_t.p0.copy()\n",
    "imp[imp < 0] = 0\n",
    "imp['Interconnectors Import'] = imp.sum(axis=1)\n",
    "interconnector_import = imp[['Interconnectors Import']]\n",
    "p_by_type = pd.concat([p_by_type, interconnector_import], axis=1)\n",
    "\n",
    "# Including Interconnectors Export (note that post-processing occurs later in script)\n",
    "exp = network.links_t.p0.copy()\n",
    "exp[exp > 0] = 0\n",
    "exp['Interconnectors Export'] = exp.sum(axis=1)\n",
    "interconnector_export = exp[['Interconnectors Export']]\n",
    "\n",
    "# Renaming Interconnector Import\n",
    "p_by_type = p_by_type.rename(columns={'Interconnector': 'Interconnectors Import'})\n",
    "print(p_by_type.loc[:, 'Wave power'])\n",
    "print(p_by_type.loc[:, 'Tidal stream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns where generation is zero\n",
    "p_by_type = p_by_type.loc[:, p_by_type.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all negative generation values to zero\n",
    "p_by_type[p_by_type < 0] = 0 # ideally stacked area chart would show all generation and charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each generation/storage/interconnector type (note that Interconnector Export colour not defined in this way)\n",
    "\n",
    "colors = {'Anaerobic Digestion': 'darkgoldenrod',\n",
    "          'Biomass (co-firing)': 'yellowgreen',\n",
    "          'Biomass (dedicated)': 'olivedrab',\n",
    "          'CCGT': 'red',\n",
    "          'CCS Biomass': 'darkolivegreen',\n",
    "          'CCS Gas': 'lightcoral',\n",
    "          'Diesel': 'lightgrey',\n",
    "          'EfW Incineration': 'chocolate',\n",
    "          'Floating Wind': 'royalblue',\n",
    "          'Hydro': 'teal',\n",
    "          'Hydrogen': 'paleturquoise',\n",
    "          'Landfill Gas': 'olive',\n",
    "          'Nuclear': 'lime',\n",
    "          'OCGT': 'red',\n",
    "          'Sewage Sludge Digestion': 'saddlebrown',\n",
    "          'Solar Photovoltaics': 'yellow',\n",
    "          'Tidal lagoon': 'mediumblue',\n",
    "          'Tidal stream': 'midnightblue',\n",
    "          'Unmet Load': 'black',\n",
    "          'Wave power': 'steelblue',\n",
    "          'Wind Offshore': 'cornflowerblue',\n",
    "          'Wind Onshore': 'mediumseagreen',\n",
    "          'Battery': 'mediumorchid',\n",
    "          'Compressed Air': 'plum',\n",
    "          'Liquid Air': 'thistle',\n",
    "          'Pumped Storage Hydroelectric': 'deepskyblue',\n",
    "          'Interconnectors Import': 'palevioletred'\n",
    "         }\n",
    "\n",
    "#           'Coal': 'dimgrey',\n",
    "#           'Oil': 'red',\n",
    "#           'Biomass': 'greenyellow',       \n",
    "#           'Interconnectors Export': 'crimson',          \n",
    "#           'Sour gas': 'darkred',\n",
    "#           'Natural Gas': 'coral',\n",
    "#           'Large Hydro': 'darkturquoise',\n",
    "#           'Small Hydro': 'turquoise',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot network-wide generation time series by generation type\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "(p_by_type / 1e3).plot(\n",
    "    kind='area', ax=ax, linewidth=0,\n",
    "    color=[colors[col] for col in p_by_type.columns])\n",
    "\n",
    "# stacked area plot of negative values, prepend column names with '_' such that they don't appear in the legend\n",
    "(interconnector_export / 1e3).plot.area(ax=ax, stacked=True, linewidth=0.)\n",
    "\n",
    "# rescale the y axis\n",
    "ax.set_ylim([(interconnector_export / 1e3).sum(axis=1).min(), (p_by_type / 1e3).sum(axis=1).max()])\n",
    "\n",
    "# Shrink current axis's height by 10% on the bottom\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "ax.set_ylabel('GW')\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Emissions by Generation Type (including Interconnectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section calculates a time series of emissions from each generation type according to the real power time series calculated in the previous section.  Note that these data include the emissions from interconnection, which is an important consideration - whether gross emissions from GB power sector include continental emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # arrange p_by_type columns into alphabetical order to ensure consistency with EI factors\n",
    "p_by_type = p_by_type[sorted(p_by_type.columns)]\n",
    "\n",
    "# create a numpy array from a list of generation types, from top row of generation mix dataframe\n",
    "types = np.asarray(list(p_by_type.columns.values))\n",
    "\n",
    "# reading in the emissions intensity data contained in relevant .csv as a dataframe\n",
    "emissions_intensity = pd.read_csv('emissions_intensity_by_types.csv')\n",
    "emissions_intensity_LOPF = emissions_intensity[emissions_intensity['Type'].isin(types)]\n",
    "emissions_intensity_LOPF.sort_values('Type')\n",
    "EI_factors = emissions_intensity_LOPF['Emissions Intensity [gCO2/kWh]'].to_numpy()\n",
    "\n",
    "# Create energy generation mix dataframe by multiplying power generation mix by the time step [MWh]\n",
    "E_by_type = p_by_type.multiply(time_step)\n",
    "\n",
    "# Create emissions dataframe. Multiply all columns in the energy dataframe by the numpy array of emissions intensity factors\n",
    "Emit_by_type = E_by_type.multiply(EI_factors, axis=1)\n",
    "\n",
    "# Convert gCO2/kWh * MWh to teCO2; the quotient of kWh:MWh (1e3) and gCO2:teCO2 (1e6) = 1e3\n",
    "Emit_by_type_te = Emit_by_type.div(1e3)\n",
    "Emit_by_type_te = Emit_by_type_te.loc[:, Emit_by_type_te.any()]\n",
    "Emit_by_type_te.to_csv('Emit_by_type_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "(Emit_by_type_te).plot(\n",
    "    kind=\"area\", ax=ax, linewidth=0,\n",
    "    color=[colors[col] for col in Emit_by_type_te.columns])\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_ylabel(\"tonne CO2\")\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions Intensity (including Interconnectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series of the network-wide (including continental interconnectors) emissions intensity is determined below.  This is repeated later in the notebook, but excludes interconnectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series of total emissions in tonnes (sum of emissions from all types - including interconnectors unless explicitly modified)\n",
    "Total_Emit_t_te = Emit_by_type_te.sum(axis=1)\n",
    "\n",
    "# Energy delivered to the grid at each time step\n",
    "Total_E_t = E_by_type.sum(axis=1)\n",
    "\n",
    "# The grid-wide emissions intensity in gCO2/kWh at each time step is given by:\n",
    "EI_gCO2 = Total_Emit_t_te * 1e3 / Total_E_t\n",
    "EI_gCO2.to_csv('EI_gCO2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Emissions Intensity (including Interconnectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average emissions intensity over the period, method 1 = quotient of sums:\n",
    "EI_avg_gCO2 = 1e3 * sum(Total_Emit_t_te) / sum(Total_E_t)\n",
    "print(\"Average emissions intensity over the period, Method 1 = \", EI_avg_gCO2, \"gCO2/kWh\")\n",
    "\n",
    "# Average emissions intensity over the period, method 2 = mean of dataframe:\n",
    "print(\"Average emissions intensity over the period, Method 2 = \", EI_gCO2.mean(), \"gCO2/kWh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions by Node (excluding Interconnectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emissions intensity arising at each node can be calculated by inspection of the generation mix at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main data originates from a pypsa network object: real power time series from each generator before node aggregation\n",
    "power_t_by_generator = network.generators_t.p\n",
    "\n",
    "# Create a list of generators and their <bus>/<types>, in the same sequence as above\n",
    "generators_by_bus = network.generators.bus\n",
    "generators_by_type = network.generators.type\n",
    "power_t_by_generator.loc[len(power_t_by_generator)] = generators_by_bus\n",
    "power_t_by_generator.loc[len(power_t_by_generator)] = generators_by_type\n",
    "power_t_by_generator.to_csv('power_t_by_generator.csv')\n",
    "\n",
    "# NB: This treatment can require the kernal to be restarted if run (and therefore executes appending) multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('power_t_by_generator.csv')\n",
    "\n",
    "# create new df for generator information (bus/type) only\n",
    "loc_and_type = df.iloc[len(df.index) - 2:, :].T\n",
    "loc_and_type['sitename'] = loc_and_type.index.values\n",
    "loc_and_type.columns= ['location', 'type', 'sitename']\n",
    "loc_and_type = loc_and_type[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extant csv\n",
    "os.remove('power_t_by_generator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove site (bus/type) information from power data\n",
    "df.drop(labels=[(len(df)-2),(len(df)-1)], axis=0, inplace=True)\n",
    "long_table = pd.melt(df, id_vars='snapshot', var_name='sitename', value_name='power')\n",
    "long_table = long_table.merge(loc_and_type, on='sitename')\n",
    "long_table['power'] = pd.to_numeric(long_table['power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = long_table.groupby(by=['snapshot', 'location', 'type']).sum()\n",
    "grouped = grouped.reset_index(level=0)\n",
    "grouped = grouped.reset_index(level=0)\n",
    "grouped = grouped.reset_index(level=0)\n",
    "wide_table_0 = grouped.pivot(index='snapshot', columns=['location', 'type'])['power']\n",
    "wide_table_0.to_csv('wide_table_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove types (columns) where no real power is generated\n",
    "wide_table = grouped.pivot(index='snapshot', columns=['location', 'type'])['power']\n",
    "wide_table.drop(columns=wide_table.columns[wide_table.sum()==0], inplace=True)\n",
    "wide_table.to_csv('wide_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of emissions intensity data by reading in the emissions intensity data contained in relevant .csv\n",
    "emissions_intensity = pd.read_csv('emissions_intensity_by_types.csv')\n",
    "emissions_intensity.columns = ['Type', 'EI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector of all the types for the full dataset\n",
    "df2 = wide_table.columns\n",
    "types_full = df2.get_level_values(1)\n",
    "types_full = pd.DataFrame(types_full.values)\n",
    "types_full.columns =['Types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create long list of all emissions intensity ordered by the real power generation table\n",
    "EI_full = types_full.replace(dict(zip(emissions_intensity.Type, emissions_intensity.EI)))\n",
    "EI_full = EI_full.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create energy generation mix dataframe by multiplying power generation mix by the time step [MWh]\n",
    "E_by_type_node = wide_table.multiply(time_step)\n",
    "E_by_type_node_0 = wide_table_0.multiply(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All emissions, including types (and locations) with zero emissions\n",
    "emis_0 = pd.DataFrame(E_by_type_node.values*EI_full.values, columns=E_by_type_node.columns, index=E_by_type.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove types (columns) with zero emissions\n",
    "emis = emis_0\n",
    "emis.drop(columns=emis.columns[emis.sum()==0], inplace=True)\n",
    "emis_bus = emis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum emissions by type at each location\n",
    "emis_bus = emis_bus.groupby(by=['location']).sum()\n",
    "emis_bus = emis_bus.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gCO2/kWh * MWh to teCO2; the quotient of kWh:MWh (1e3) and gCO2:teCO2 (1e6) = 1e3\n",
    "emis_by_bus_te = emis_bus.div(1e3)\n",
    "emis_by_bus_te.to_csv('emis_by_bus_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot how the emissions in tonnes changes at each node in time - no interconnectors, hence different to previous treatment\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "(emis_by_bus_te).plot(\n",
    "    kind=\"area\", ax=ax, linewidth=0)\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "ax.set_ylabel(\"tonne CO2\")\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions Intensity (excluding Interconnectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total grid-wise emissions in tonnes of grid at each time step, excluding interconnectors\n",
    "emis_te_ex_int = emis_by_bus_te.sum(axis=1)\n",
    "\n",
    "# Grid-wise energy delivered at each time step\n",
    "E_ex_int = E_by_type.drop(columns = 'Interconnectors Import')\n",
    "E_ex_int = E_ex_int.sum(axis=1)\n",
    "\n",
    "# casting new index to ensure compatibility for division\n",
    "emis_te_ex_int.index = E_ex_int.index\n",
    "\n",
    "# The grid-wide emissions intensity in gCO2/kWh at each time step is given by:\n",
    "EI_gCO2_ex_int = emis_te_ex_int * 1e3 / E_ex_int\n",
    "EI_gCO2_ex_int.to_csv('EI_gCO2_ex_int.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Emissions Intensity (excluding Interconnectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average emissions intensity over the period, method 1 = quotient of sums:\n",
    "EI_gCO2_ex_int_avg = 1e3 * sum(emis_te_ex_int) / sum(E_ex_int)\n",
    "print(\"Method 1 = \", EI_gCO2_ex_int_avg, \"gCO2/kWh\")\n",
    "\n",
    "# Average emissions intensity over the period, method 2 = mean of dataframe:\n",
    "print(\"Method 2 = \", EI_gCO2_ex_int.mean(), \"gCO2/kWh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodal Emissions Intensity (excluding Interconnectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emissions intensity at each location can be considered per time step, or averaged over the period.  The variation in emissions intensity is plotted in time at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum energy by type at each node [MWh]\n",
    "E_by_node = E_by_type_node.T\n",
    "E_by_node = E_by_node.groupby(by=['location']).sum()\n",
    "E_by_node = E_by_node.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting new index to ensure compatibility for division\n",
    "E_by_node.index = emis_by_bus_te.index\n",
    "E_by_node.to_csv('E_by_node.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emissions intensity by node\n",
    "EI_by_node = 1e3 * emis_by_bus_te  / E_by_node\n",
    "EI_by_node.fillna(0, inplace=True) # set NaN to zero - created when emissions at a node don't appear because all nodal generation is zero emissions\n",
    "EI_by_node['Average'] = EI_by_node.mean(axis=1) # create new column containing the average across all nodes\n",
    "EI_by_node.to_csv('EI_by_node.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how the emissions intensity in [gCO2/kWh] changes at each node in time (zero emissions intensity not shown)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(15,10)\n",
    "EI_by_node.plot(ax = ax)\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5)\n",
    "ax.set_ylabel(\"gCO2/kWh\")\n",
    "ax.set_xlabel(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Nodal Emissions Intensity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average emissions intensity over the period at each location can be plotted to consider local emissions.  The variation in emissions intensity is plotted in time at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a time stamp - note this is set up for the final time step, not an average value\n",
    "# The time stamp 'now' is not critical though as 'network' object is constant within each run and average defined elsewhere\n",
    "now = network.snapshots[len(emis_by_bus_te)-1] \n",
    "\n",
    "# required order of buses for plotting on map is given by network object:\n",
    "bus_order = network.buses_t.marginal_price.loc[now] # type = series.\n",
    "bus_order = bus_order[:].index\n",
    "frame = { 'location': bus_order }\n",
    "bus_order_df = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gross emissions at all buses (including zero emission buses) in tonnes\n",
    "emis_0_bus = emis_0.T\n",
    "emis_0_bus = emis_0_bus.groupby(by=['location']).sum()\n",
    "emis_0_bus = emis_0_bus.T\n",
    "emis_0_by_bus_te = emis_0_bus.div(1e3) #; emis_0_by_bus_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum energy by type at each node (including zero emission buses) in MWh\n",
    "E_by_node_0 = E_by_type_node_0.T\n",
    "E_by_node_0 = E_by_node_0.groupby(by=['location']).sum()\n",
    "E_by_node_0 = E_by_node_0.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting new index to ensure compatibility for division\n",
    "E_by_node_0.index = emis_0_by_bus_te.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating average emissions intensity by node\n",
    "EI_0_by_node = 1e3 * emis_0_by_bus_te  / E_by_node_0\n",
    "EI_0_by_node.fillna(0) # set NaN to zero - created when emissions at a node don't appear because all nodal generation is zero emissions\n",
    "EI_0_by_node['Average'] = EI_0_by_node.mean(axis=1) # create new column containing the average across all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average emissions intensity at each bus over the period (series)\n",
    "EI_0_by_node_avg = EI_0_by_node.mean()\n",
    "EI_0_by_node_avg = EI_0_by_node_avg.drop(labels = 'Average')\n",
    "EI_0_by_node_avg = EI_0_by_node_avg.fillna(0)\n",
    "EI_0_by_node_avg = EI_0_by_node_avg.to_frame().reset_index()\n",
    "EI_0_by_node_avg.columns = ['location', 'EI_avg']; \n",
    "\n",
    "# define EI at interconnectors (exogeneous)\n",
    "interconnectors = pd.DataFrame({'location': ['Netherlands',\n",
    "                                             'Belgium',\n",
    "                                             'France1',\n",
    "                                             'France2',\n",
    "                                             'Ireland',\n",
    "                                             'Germany',\n",
    "                                             'Ireland2',\n",
    "                                             'Norway',\n",
    "                                             'Denmark'],\n",
    "                    'EI_avg': [10, 10, 10, 10, 10, 10, 10, 10, 10]}) # test figures to check location\n",
    "\n",
    "#add new row to end of DataFrame\n",
    "EI_0_by_node_avg = EI_0_by_node_avg.append(interconnectors, ignore_index = True)\n",
    "\n",
    "df_merge = pd.merge(bus_order_df, EI_0_by_node_avg, on=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating figure\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "network.plot(ax=ax, line_widths=pd.Series(0.5, network.lines.index))\n",
    "plt.hexbin(network.buses.x, network.buses.y,\n",
    "           gridsize=20,\n",
    "           C=df_merge['EI_avg'],\n",
    "           cmap=plt.cm.jet)\n",
    "\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Average emissions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPSA-GB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
